{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "joint-briefing",
   "metadata": {},
   "source": [
    "# Run analysis on multiple files\n",
    "\n",
    "- The simulations should be in the form of distinct folders containing results for different parameters within the specified folder as follows:\n",
    "\n",
    "data_folder\n",
    "   - sim_folder_1\n",
    "   - sim_folder_2\n",
    "   - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'init_modules' in globals().keys():\n",
    "    # second or subsequent run: remove all but initially loaded modules\n",
    "    for m in sys.modules.keys():\n",
    "        if m not in init_modules:\n",
    "            del(sys.modules[m])\n",
    "else:\n",
    "    # first run: find out which modules were initially loaded\n",
    "    init_modules = sys.modules.keys()\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import pyfilaments.analysisutils as analysis\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "linear-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No:of Simulation files:  40\n"
     ]
    }
   ],
   "source": [
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/analysis_test'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/b0_2_1_FullSweep_Final'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/FinerResolution_BendingStiffness'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-06-23'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-08-18'\n",
    "# data_folder = '/home/deepak/Dropbox/LacryModeling/ModellingResults/StochasticActivity/NormalDistribution'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/b0_2_1_FullSweep_Final/activity_time_750'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/FilamentLength_Sweeps/activity_time_750'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-08-28'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-10-19'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrength_sweep'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-11-08'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ConstantCompressiveActivity_sweep'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-11-25'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-12-02'\n",
    "\n",
    "# Axial stiffness sweep\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrength_sweep_k_10_kappa_6.25'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrength_sweep_k_100_kappa_6.25'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrength_sweep_RandomAnglesIC'\n",
    "\n",
    "data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/Analysis_test'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrengthSweeps_diffActivityTimescales/activity_timescale_700'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityTimeSweep_constantActivity_1.5'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/StochasticActivity/NormalDistribution/noise_0_05'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/StochasticActivity/DeterministicActivity'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrengthSweeps_diffActivityTimeScales_FINAL'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrengthSweep_widerICS_FINAL_2021-12-23'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrengthSweep_FineResolution'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/DistributedActivitySims_2022_11_11'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2022-11-12'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrengthSweeps_diffActivityTimeScales_FINAL/activityTime_500'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityTimeSweep_constantActivity_1.5'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityTimeSweep_FINAL'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/DistributedActivity_LacryType/NeckHead_scalefactor_2'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/DistributedActivitySims_2022_11_11'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2022-12-27'\n",
    "\n",
    "# Find all simulation data files and create a list\n",
    "files_list = []\n",
    " # Walk through the folders and identify the simulation data files\n",
    "for dirs, subdirs, files in os.walk(data_folder, topdown=False):\n",
    "\n",
    "    root, subFolderName = os.path.split(dirs)\n",
    "\n",
    "    for fileNames in files:\n",
    "        if(fileNames.endswith('hdf5') and fileNames[0] != '.' and 'analysis' not in fileNames and 'ic' not in fileNames and 'eigenvectors' not in fileNames):\n",
    "            files_list.append(os.path.join(dirs,fileNames))\n",
    "#         if(fileNames.endswith('hdf5') and fileNames[0] != '.' and fileNames == 'SimResults_00.hdf5'):\n",
    "#             files_list.append(os.path.join(dirs,fileNames))\n",
    "\n",
    "print('No:of Simulation files: ', len(files_list))\n",
    "\n",
    "\n",
    "    \n",
    "N_ACTIVITY_CYCLES = 400 # No:of activity cycles requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "promotional-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_filament_analysis(file):\n",
    "    print('Analyzing file ...')\n",
    "    print(file)\n",
    "\n",
    "    filament = analysis.analysisTools(file = file)\n",
    "    \n",
    "\n",
    "    root_folder, file_name = os.path.split(file)\n",
    "    \n",
    "    # @@@ Better to use Metadata from the HDF5 file so there is no possible delinking of data and metadata\n",
    "    df = pd.DataFrame({'N particles':[filament.Np],'radius':[filament.radius],'bond length':[filament.b0],\n",
    "                       'spring constant':[filament.k], 'kappa_hat':[filament.kappa_hat], \n",
    "                       'force strength':[filament.F0], 'stresslet strength':[filament.S0], \n",
    "                       'potDipole strength':[filament.D0], 'simulation type':[filament.sim_type], \n",
    "                       'boundary condition 0':[filament.bc[0]], 'boundary condition 1':[filament.bc[-1]], \n",
    "                       ' activity time scale':[filament.activity_timescale], 'viscosity':[filament.mu]})\n",
    "    \n",
    "    # Calculate dimensionless numbers\n",
    "    filament.time_scales()\n",
    "    filament.compute_scales()\n",
    "    filament.compute_dimensionless_groups()\n",
    "    \n",
    "    periodic_flag = False \n",
    "    min_period = None\n",
    "    threshold_index = int(0)  # Activity cycle when the dynamics transitions to a periodic cycle\n",
    "    \n",
    "    \n",
    "    # Filament tip coverage analysis\n",
    "    filament.filament_tip_coverage(save = True, overwrite = True)\n",
    "    \n",
    "    # Calculate the search efficiency\n",
    "    search_efficiency = filament.search_efficiency()\n",
    "    \n",
    "    print(filament.activity_timescale)\n",
    "    # Check if simulation was completed or terminated before completion\n",
    "    if(int(filament.Time[-1]) >= int(filament.activity_timescale*N_ACTIVITY_CYCLES)):\n",
    "        simulation_completed = True\n",
    "        # Classify the dynamics\n",
    "        periodic_flag, min_period, threshold_index = filament.classify_filament_dynamics()\n",
    "    else:\n",
    "        simulation_completed = False\n",
    "        \n",
    "    \n",
    "    activity_cycles_completed = int(filament.Time[-1]/filament.activity_timescale)\n",
    "    \n",
    "    if(periodic_flag == False):\n",
    "        # if dynamics is aperiodic\n",
    "        df['period'] = float(np.nan)\n",
    "        df['threshold index'] = int(0)\n",
    "    else:\n",
    "        df['period'] = min_period\n",
    "        df['threshold index'] = int(threshold_index)\n",
    "        \n",
    "        \n",
    "    df['simulation completed'] = simulation_completed\n",
    "    df['periodic dynamics'] = periodic_flag\n",
    "    \n",
    "    print('Periodic dynamics:', df['periodic dynamics'])\n",
    "    print('Period:', df['period'])\n",
    "    \n",
    "    df['max unique locations'] = filament.derived_data['unique position count'][-1]\n",
    "    df['activity cycles completed'] = activity_cycles_completed\n",
    "    \n",
    "    print('Activity cycles completed: {}'.format(activity_cycles_completed))\n",
    "    \n",
    "    df['search efficiency'] = search_efficiency\n",
    "    \n",
    "    df['activity number'] = filament.activity_number\n",
    "    \n",
    "#     df['activity type'] =  filament.activity['type']\n",
    "#     df['noise scale'] =  filament.activity['noise_scale']\n",
    "    \n",
    "    filament_buckling = filament.detect_buckling()\n",
    "    \n",
    "    print(filament_buckling)\n",
    "    \n",
    "    if periodic_flag==True:\n",
    "        \n",
    "        if min_period==1 and filament_buckling==False:\n",
    "            df['filament behavior'] = 'no buckling'\n",
    "        elif min_period==1 and filament_buckling == True:\n",
    "            df['filament behavior'] = '1-period'\n",
    "        elif min_period%2==0:\n",
    "            df['filament behavior']= '2n-period'\n",
    "        else:\n",
    "            df['filament behavior'] = 'odd-period'\n",
    "    else:\n",
    "        df['filament behavior'] = 'aperiodic'\n",
    "        \n",
    "    if simulation_completed == False:\n",
    "        df['filament behavior'] = 'escape'\n",
    "    \n",
    "    # Calculate the filament tip angles (at constant phase) and save them to a file\n",
    "    \n",
    "    phase = 0\n",
    "    angles = filament.compute_basetip_angle_at_constant_phase(phase_value = phase)\n",
    "    \n",
    "#     print(angles)\n",
    "    \n",
    "    \n",
    "    # Save the analysis data\n",
    "    save_file = file_name[:-5] + '_analysis.csv'\n",
    "    save_folder = os.path.join(root_folder, 'Analysis')\n",
    "\n",
    "    if(not os.path.exists(save_folder)):\n",
    "        os.makedirs(save_folder)\n",
    "        \n",
    "    df.to_csv(os.path.join(save_folder, save_file))\n",
    "    \n",
    "    # Create a dataset and save the data\n",
    "    save_file = file_name[:-5] + '_analysis.hdf5'\n",
    "\n",
    "\n",
    "    with h5py.File(os.path.join(save_folder, save_file), \"w\") as f:\n",
    "        dset = f.create_group(\"analysis data\")\n",
    "        dset.attrs['N particles'] = filament.Np\n",
    "        dset.attrs['radius'] = filament.radius\n",
    "        dset.attrs['bond length'] = filament.b0\n",
    "        dset.attrs['spring constant'] = filament.k\n",
    "        dset.attrs['kappa_hat'] = filament.kappa_hat\n",
    "        dset.attrs['force strength'] = filament.F0\n",
    "        dset.attrs['stresslet strength'] = filament.S0\n",
    "        dset.attrs['potDipole strength'] = filament.D0\n",
    "        dset.attrs['simulation type'] = filament.sim_type\n",
    "        dset.attrs['activity timescale'] = filament.activity_timescale\n",
    "        dset.attrs['viscosity'] = filament.mu\n",
    "        dset.attrs['boundary condition 0'] = filament.bc[0]\n",
    "        dset.attrs['boundary condition 1'] = filament.bc[-1]\n",
    "        dset.attrs['threshold cycle'] = df['threshold index']  # This is the cause of the issue...\n",
    "        \n",
    "        print(periodic_flag)\n",
    "        print(min_period)\n",
    "        dset.attrs['activity cycles completed'] = activity_cycles_completed\n",
    "\n",
    "        dset.attrs['Sim complete'] = int(simulation_completed)\n",
    "\n",
    "        dset.attrs['periodic'] = df['periodic dynamics']\n",
    "        dset.attrs['period'] =  df['period']\n",
    "        \n",
    "        dset.attrs['constant phase'] = phase\n",
    "        dset.create_dataset(\"Tip angles\", data = angles)\n",
    "        \n",
    "        dset.attrs['activity number'] = filament.activity_number\n",
    "        dset.attrs['filament behavior'] = df['filament behavior'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "frozen-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s][Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      " 30%|███       | 12/40 [00:00<00:00, 84.39it/s][Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    5.2s\n",
      " 60%|██████    | 24/40 [00:05<00:04,  3.98it/s][Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    8.9s\n",
      "100%|██████████| 40/40 [00:11<00:00,  3.53it/s]\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=12)]: Done  22 out of  40 | elapsed:   15.2s remaining:   12.4s\n",
      "[Parallel(n_jobs=12)]: Done  27 out of  40 | elapsed:   16.2s remaining:    7.8s\n",
      "[Parallel(n_jobs=12)]: Done  32 out of  40 | elapsed:   18.1s remaining:    4.5s\n",
      "[Parallel(n_jobs=12)]: Done  37 out of  40 | elapsed:   21.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done  40 out of  40 | elapsed:   40.5s finished\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "num_cores = 12\n",
    "\n",
    "results = Parallel(n_jobs=num_cores,  verbose=10)(delayed(run_filament_analysis)(file) for file in tqdm(files_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-chance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
