{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "joint-briefing",
   "metadata": {},
   "source": [
    "# Run analysis on multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "domestic-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import pyfilaments.analysisutils as analysis\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "linear-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021-08-28', '2021-10-19', '2021-10-21', '2021-10-20', '2021-08-20']\n",
      "No:of Simulation files:  620\n"
     ]
    }
   ],
   "source": [
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/analysis_test'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/b0_2_1_FullSweep_Final'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/FinerResolution_BendingStiffness'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-06-23'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-08-18'\n",
    "# data_folder = '/home/deepak/Dropbox/LacryModeling/ModellingResults/StochasticActivity/NormalDistribution'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/b0_2_1_FullSweep_Final/activity_time_750'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/FilamentLength_Sweeps/activity_time_750'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-08-28'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-10-19'\n",
    "\n",
    "data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ActivityStrength_sweep'\n",
    "\n",
    "print(os.listdir(data_folder))\n",
    "\n",
    "# Find all simulation data files and create a list\n",
    "files_list = []\n",
    " # Walk through the folders and identify the simulation data files\n",
    "for dirs, subdirs, files in os.walk(data_folder, topdown=False):\n",
    "\n",
    "    root, subFolderName = os.path.split(dirs)\n",
    "\n",
    "    for fileNames in files:\n",
    "        if(fileNames.endswith('hdf5') and fileNames[0] != '.' and 'analysis' not in fileNames):\n",
    "            files_list.append(os.path.join(dirs,fileNames))\n",
    "#         if(fileNames.endswith('hdf5') and fileNames[0] != '.' and fileNames == 'SimResults_00.hdf5'):\n",
    "#             files_list.append(os.path.join(dirs,fileNames))\n",
    "\n",
    "print('No:of Simulation files: ', len(files_list))\n",
    "\n",
    "def run_filament_analysis(file):\n",
    "    print('Analyzing file ...')\n",
    "    print(file)\n",
    "\n",
    "    filament = analysis.analysisTools(file = file)\n",
    "\n",
    "\n",
    "    root_folder, file_name = os.path.split(file)\n",
    "    \n",
    "    # @@@ Better to use Metadata from the HDF5 file so there is no possible delinking of data and metadata\n",
    "    df = pd.DataFrame({'N particles':[filament.Np],'radius':[filament.radius],'bond length':[filament.b0],\n",
    "                       'spring constant':[filament.k], 'kappa_hat':[filament.kappa_hat], \n",
    "                       'force strength':[filament.F0], 'stresslet strength':[filament.S0], \n",
    "                       'potDipole strength':[filament.D0], 'simulation type':[filament.sim_type], \n",
    "                       'boundary condition 0':[filament.bc[0]], 'boundary condition 1':[filament.bc[-1]], \n",
    "                       ' activity time scale':[filament.activity_timescale], 'viscosity':[filament.mu]})\n",
    "    \n",
    "    periodic_flag = False \n",
    "    min_period = None\n",
    "    threshold_index = 0  # Activity cycle when the dynamics transitions to a periodic cycle\n",
    "    \n",
    "    filament.filament_tip_coverage(save = True)\n",
    "    # Check if simulation was completed or terminated before completion\n",
    "    if(int(filament.Time[-1]) == int(filament.activity_timescale*500)):\n",
    "        simulation_completed = True\n",
    "        # Classify the dynamics\n",
    "        periodic_flag, min_period, threshold_index = filament.classify_filament_dynamics()\n",
    "    else:\n",
    "        simulation_completed = False\n",
    "        \n",
    "    activity_cycles_completed = int(filament.Time[-1]/filament.activity_timescale)\n",
    "    \n",
    "    if(min_period is None):\n",
    "        # if dynamics is aperiodic\n",
    "        \n",
    "        df['period'] = float(np.nan)\n",
    "        df['threshold index'] = 0\n",
    "    else:\n",
    "        df['period'] = min_period\n",
    "        df['threshold index'] = threshold_index\n",
    "        \n",
    "        \n",
    "    df['simulation completed'] = simulation_completed\n",
    "    df['periodic dynamics'] = periodic_flag\n",
    "    df['max unique locations'] = filament.derived_data['unique position count'][-1]\n",
    "    df['activity cycles completed'] = activity_cycles_completed\n",
    "    \n",
    "    print('Activity cycles completed: {}'.format(activity_cycles_completed))\n",
    "    \n",
    "    # Calculate the filament tip angles (at constant phase) and save them to a file\n",
    "    \n",
    "    phase = 0\n",
    "    angles = filament.compute_tip_angle_at_constant_phase(phase_value = phase)\n",
    "    print(angles)\n",
    "    \n",
    "    \n",
    "\n",
    "    save_file = file_name[:-5] + '_analysis.csv'\n",
    "    save_folder = os.path.join(root_folder, 'Analysis')\n",
    "\n",
    "    if(not os.path.exists(save_folder)):\n",
    "        os.makedirs(save_folder)\n",
    "    df.to_csv(os.path.join(save_folder, save_file))\n",
    "    \n",
    "    # Create a dataset and save the data\n",
    "    save_file = file_name[:-5] + '_analysis.hdf5'\n",
    "\n",
    "\n",
    "    with h5py.File(os.path.join(save_folder, save_file), \"w\") as f:\n",
    "        dset = f.create_group(\"analysis data\")\n",
    "        dset.attrs['N particles'] = filament.Np\n",
    "        dset.attrs['radius'] = filament.radius\n",
    "        dset.attrs['bond length'] = filament.b0\n",
    "        dset.attrs['spring constant'] = filament.k\n",
    "        dset.attrs['kappa_hat'] = filament.kappa_hat\n",
    "        dset.attrs['force strength'] = filament.F0\n",
    "        dset.attrs['stresslet strength'] = filament.S0\n",
    "        dset.attrs['potDipole strength'] = filament.D0\n",
    "        dset.attrs['simulation type'] = filament.sim_type\n",
    "        dset.attrs['activity time scale'] = filament.activity_timescale\n",
    "        dset.attrs['viscosity'] = filament.mu\n",
    "        dset.attrs['boundary condition 0'] = filament.bc[0]\n",
    "        dset.attrs['boundary condition 1'] = filament.bc[-1]\n",
    "        dset.attrs['Sim complete'] = simulation_completed\n",
    "        dset.attrs['activity cycles completed'] = activity_cycles_completed\n",
    "        dset.attrs['threshold cycle'] = df['threshold index']\n",
    "        \n",
    "#         print(periodic_flag)\n",
    "#         print(min_period)\n",
    "        dset.attrs['periodic'] = df['periodic dynamics']\n",
    "        dset.attrs['period'] =  df['period']\n",
    "        \n",
    "        dset.attrs['constant phase'] = phase\n",
    "        dset.create_dataset(\"Tip angles\", data = angles)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "frozen-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/620 [00:00<?, ?it/s]\u001b[A[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "\n",
      "  2%|▏         | 12/620 [00:00<00:07, 81.75it/s]\u001b[A[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    1.8s\n",
      "\n",
      "  4%|▍         | 24/620 [00:01<00:50, 11.89it/s]\u001b[A[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    2.9s\n",
      "\n",
      "  6%|▌         | 36/620 [00:03<00:55, 10.49it/s]\u001b[A[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    6.1s\n",
      "\n",
      "  8%|▊         | 48/620 [00:06<01:38,  5.81it/s]\u001b[A[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:   18.9s\n",
      "\n",
      " 10%|▉         | 60/620 [00:18<04:30,  2.07it/s]\u001b[A[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:   37.4s\n",
      "\n",
      " 12%|█▏        | 72/620 [00:37<07:41,  1.19it/s]\u001b[A[Parallel(n_jobs=12)]: Done  61 tasks      | elapsed:   40.1s\n",
      "\n",
      " 14%|█▎        | 84/620 [00:40<05:43,  1.56it/s]\u001b[A\n",
      " 15%|█▌        | 96/620 [00:47<05:34,  1.57it/s]\u001b[A[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:   47.9s\n",
      "\n",
      " 17%|█▋        | 108/620 [00:52<04:45,  1.79it/s]\u001b[A[Parallel(n_jobs=12)]: Done  89 tasks      | elapsed:   56.3s\n",
      "\n",
      " 19%|█▉        | 120/620 [01:06<06:17,  1.33it/s]\u001b[A[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:  1.2min\n",
      "\n",
      " 21%|██▏       | 132/620 [01:17<06:25,  1.27it/s]\u001b[A[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:  1.7min\n",
      "\n",
      " 23%|██▎       | 144/620 [01:39<08:47,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 156/620 [01:59<09:57,  1.29s/it]\u001b[A[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:  2.1min\n",
      "\n",
      " 27%|██▋       | 168/620 [02:11<08:59,  1.19s/it]\u001b[A[Parallel(n_jobs=12)]: Done 157 tasks      | elapsed:  2.4min\n",
      "\n",
      " 29%|██▉       | 180/620 [02:22<08:12,  1.12s/it]\u001b[A\n",
      " 31%|███       | 192/620 [02:34<07:46,  1.09s/it]\u001b[A[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:  2.7min\n",
      "\n",
      " 33%|███▎      | 204/620 [02:53<08:29,  1.23s/it]\u001b[A\n",
      " 35%|███▍      | 216/620 [03:02<07:16,  1.08s/it]\u001b[A[Parallel(n_jobs=12)]: Done 197 tasks      | elapsed:  3.1min\n",
      "\n",
      " 37%|███▋      | 228/620 [03:07<05:46,  1.13it/s]\u001b[A\n",
      " 39%|███▊      | 240/620 [03:15<05:08,  1.23it/s]\u001b[A[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:  3.3min\n",
      "\n",
      " 41%|████      | 252/620 [03:21<04:26,  1.38it/s]\u001b[A[Parallel(n_jobs=12)]: Done 241 tasks      | elapsed:  3.5min\n",
      "\n",
      " 43%|████▎     | 264/620 [03:27<03:52,  1.53it/s]\u001b[A\n",
      " 45%|████▍     | 276/620 [03:46<05:23,  1.06it/s]\u001b[A[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:  3.9min\n",
      "\n",
      " 46%|████▋     | 288/620 [03:55<04:49,  1.15it/s]\u001b[A\n",
      " 48%|████▊     | 300/620 [04:00<03:58,  1.34it/s]\u001b[A[Parallel(n_jobs=12)]: Done 289 tasks      | elapsed:  4.1min\n",
      "\n",
      " 50%|█████     | 312/620 [04:06<03:23,  1.52it/s]\u001b[A\n",
      " 52%|█████▏    | 324/620 [04:06<02:20,  2.10it/s]\u001b[A\n",
      " 54%|█████▍    | 336/620 [04:09<01:58,  2.41it/s]\u001b[A[Parallel(n_jobs=12)]: Done 314 tasks      | elapsed:  4.2min\n",
      "\n",
      " 56%|█████▌    | 348/620 [04:22<02:43,  1.66it/s]\u001b[A\n",
      " 58%|█████▊    | 360/620 [04:38<03:37,  1.20it/s]\u001b[A[Parallel(n_jobs=12)]: Done 341 tasks      | elapsed:  4.7min\n",
      "\n",
      " 60%|██████    | 372/620 [04:50<03:39,  1.13it/s]\u001b[A\n",
      " 62%|██████▏   | 384/620 [04:57<03:07,  1.26it/s]\u001b[A[Parallel(n_jobs=12)]: Done 368 tasks      | elapsed:  5.1min\n",
      "\n",
      " 64%|██████▍   | 396/620 [05:08<03:02,  1.23it/s]\u001b[A\n",
      " 66%|██████▌   | 408/620 [05:24<03:26,  1.03it/s]\u001b[A[Parallel(n_jobs=12)]: Done 397 tasks      | elapsed:  5.4min\n",
      "\n",
      " 68%|██████▊   | 420/620 [05:26<02:27,  1.36it/s]\u001b[A\n",
      " 70%|██████▉   | 432/620 [05:32<02:05,  1.50it/s]\u001b[A\n",
      " 72%|███████▏  | 444/620 [05:47<02:27,  1.19it/s]\u001b[A[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:  5.9min\n",
      "\n",
      " 74%|███████▎  | 456/620 [06:12<03:18,  1.21s/it]\u001b[A\n",
      " 75%|███████▌  | 468/620 [06:21<02:42,  1.07s/it]\u001b[A[Parallel(n_jobs=12)]: Done 457 tasks      | elapsed:  6.7min\n",
      "\n",
      " 77%|███████▋  | 480/620 [06:44<03:05,  1.32s/it]\u001b[A\n",
      " 79%|███████▉  | 492/620 [06:49<02:14,  1.05s/it]\u001b[A\n",
      " 81%|████████▏ | 504/620 [07:01<02:00,  1.04s/it]\u001b[A[Parallel(n_jobs=12)]: Done 488 tasks      | elapsed:  7.0min\n",
      "\n",
      " 83%|████████▎ | 516/620 [07:03<01:20,  1.29it/s]\u001b[A\n",
      " 85%|████████▌ | 528/620 [07:17<01:23,  1.10it/s]\u001b[A\n",
      " 87%|████████▋ | 540/620 [07:27<01:09,  1.16it/s]\u001b[A[Parallel(n_jobs=12)]: Done 521 tasks      | elapsed:  7.5min\n",
      "\n",
      " 89%|████████▉ | 552/620 [07:33<00:52,  1.29it/s]\u001b[A\n",
      " 91%|█████████ | 564/620 [07:38<00:37,  1.50it/s]\u001b[A\n",
      " 93%|█████████▎| 576/620 [07:51<00:34,  1.27it/s]\u001b[A[Parallel(n_jobs=12)]: Done 554 tasks      | elapsed:  7.9min\n",
      "\n",
      " 95%|█████████▍| 588/620 [08:01<00:25,  1.25it/s]\u001b[A\n",
      " 97%|█████████▋| 600/620 [08:16<00:18,  1.06it/s]\u001b[A[Parallel(n_jobs=12)]: Done 589 tasks      | elapsed:  8.4min\n",
      "\n",
      "100%|██████████| 620/620 [08:26<00:00,  1.22it/s]\u001b[A\n",
      "[Parallel(n_jobs=12)]: Done 620 out of 620 | elapsed:  8.9min finished\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "num_cores = 12\n",
    "\n",
    "results = Parallel(n_jobs=num_cores,  verbose=10)(delayed(run_filament_analysis)(file) for file in tqdm(files_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "secret-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.56410256 0.62820513 0.69230769 0.75641026 0.82051282\n",
      " 0.88461538 0.94871795 1.01282051 1.07692308 1.14102564 1.20512821\n",
      " 1.26923077 1.33333333 1.3974359  1.46153846 1.52564103 1.58974359\n",
      " 1.65384615 1.71794872 1.78205128 1.84615385 1.91025641 1.97435897\n",
      " 2.03846154 2.1025641  2.16666667 2.23076923 2.29487179 2.35897436\n",
      " 2.42307692 2.48717949 2.55128205 2.61538462 2.67948718 2.74358974\n",
      " 2.80769231 2.87179487 2.93589744 3.        ]\n"
     ]
    }
   ],
   "source": [
    "print(np.linspace(0.5,3,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-symbol",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
