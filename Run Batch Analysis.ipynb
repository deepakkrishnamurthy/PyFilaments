{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "joint-briefing",
   "metadata": {},
   "source": [
    "# Run analysis on multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "domestic-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import pyfilaments.analysisutils as analysis\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "linear-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SimResults_Np_16_Shape_line_kappa_hat_6_k_25_b0_2.1_F_0_S_0_D_1.5_activityTime_750_simType_point', 'SimResults_Np_32_Shape_line_kappa_hat_6_k_25_b0_2.1_F_0_S_0_D_1.5_activityTime_750_simType_point', 'SimResults_Np_128_Shape_line_kappa_hat_6_k_25_b0_2.1_F_0_S_0_D_1.5_activityTime_750_simType_point', 'SimResults_Np_64_Shape_line_kappa_hat_6_k_25_b0_2.1_F_0_S_0_D_1.5_activityTime_750_simType_point', 'SimResults_Np_256_Shape_line_kappa_hat_6_k_25_b0_2.1_F_0_S_0_D_1.5_activityTime_750_simType_point', 'SimResults_Np_96_Shape_line_kappa_hat_6_k_25_b0_2.1_F_0_S_0_D_1.5_activityTime_750_simType_point', 'SimResults_Np_48_Shape_line_kappa_hat_6_k_25_b0_2.1_F_0_S_0_D_1.5_activityTime_750_simType_point']\n",
      "No:of Simulation files:  21\n"
     ]
    }
   ],
   "source": [
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/analysis_test'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/b0_2_1_FullSweep_Final'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/FinerResolution_BendingStiffness'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-06-23'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults'\n",
    "\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/ModellingResults/2021-08-18'\n",
    "# data_folder = '/home/deepak/Dropbox/LacryModeling/ModellingResults/StochasticActivity/NormalDistribution'\n",
    "# data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/BendingStiffnessSweeps/b0_2_1_FullSweep_Final/activity_time_750'\n",
    "\n",
    "data_folder = '/home/deepak/ActiveFilamentsSearch_backup_3/FilamentLength_Sweeps/activity_time_750'\n",
    "\n",
    "print(os.listdir(data_folder))\n",
    "\n",
    "# Find all simulation data files and create a list\n",
    "files_list = []\n",
    " # Walk through the folders and identify the simulation data files\n",
    "for dirs, subdirs, files in os.walk(data_folder, topdown=False):\n",
    "\n",
    "    root, subFolderName = os.path.split(dirs)\n",
    "\n",
    "    for fileNames in files:\n",
    "        if(fileNames.endswith('hdf5') and fileNames[0] != '.' and 'analysis' not in fileNames):\n",
    "            files_list.append(os.path.join(dirs,fileNames))\n",
    "#         if(fileNames.endswith('hdf5') and fileNames[0] != '.' and fileNames == 'SimResults_00.hdf5'):\n",
    "#             files_list.append(os.path.join(dirs,fileNames))\n",
    "\n",
    "print('No:of Simulation files: ', len(files_list))\n",
    "\n",
    "def run_filament_analysis(file):\n",
    "    print('Analyzing file ...')\n",
    "    print(file)\n",
    "\n",
    "    filament = analysis.analysisTools(file = file)\n",
    "\n",
    "\n",
    "    root_folder, file_name = os.path.split(file)\n",
    "\n",
    "    # Create a data-packet to save for further analysis\n",
    "    # Collect simulation metadata\n",
    "#     metadata_path = os.path.join(root_folder, 'metadata.csv')\n",
    "#     assert(os.path.exists(metadata_path))\n",
    "#     df = pd.read_csv(metadata_path)\n",
    "    \n",
    "    # @@@ Better to use Metadata from the HDF5 file so there is no possible delinking of data and metadata\n",
    "    df = pd.DataFrame({'N particles':[filament.Np],'radius':[filament.radius],'bond length':[filament.b0],\n",
    "                       'spring constant':[filament.k], 'kappa_hat':[filament.kappa_hat], \n",
    "                       'force strength':[filament.F0], 'stresslet strength':[filament.S0], \n",
    "                       'potDipole strength':[filament.D0], 'simulation type':[filament.sim_type], \n",
    "                       'boundary condition 0':[filament.bc[0]], 'boundary condition 1':[filament.bc[-1]], \n",
    "                       ' activity time scale':[filament.activity_timescale], 'viscosity':[filament.mu]})\n",
    "    \n",
    "    \n",
    "    periodic_flag = None \n",
    "    min_period = None\n",
    "    \n",
    "    filament.filament_tip_coverage(save = True)\n",
    "    # Check if simulation was completed or terminated before completion\n",
    "    if(int(filament.Time[-1]) == int(df[' activity time scale']*500)):\n",
    "        simulation_completed = True\n",
    "        # Classify the dynamics\n",
    "        periodic_flag, min_period = filament.classify_filament_dynamics()\n",
    "    else:\n",
    "        simulation_completed = False\n",
    "\n",
    "    df['simulation completed'] = simulation_completed\n",
    "    df['periodic dynamics'] = periodic_flag\n",
    "    df['period'] = min_period\n",
    "    df['max unique locations'] = filament.derived_data['unique position count'][-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calculate the filament tip angles (at constant phase) and save them to a file\n",
    "    \n",
    "    phase = 0\n",
    "    angles = filament.compute_tip_angle_at_constant_phase(phase_value = phase)\n",
    "    print(angles)\n",
    "    \n",
    "    \n",
    "\n",
    "    save_file = file_name[:-5] + '_analysis.csv'\n",
    "    save_folder = os.path.join(root_folder, 'Analysis')\n",
    "\n",
    "    if(not os.path.exists(save_folder)):\n",
    "        os.makedirs(save_folder)\n",
    "    df.to_csv(os.path.join(save_folder, save_file))\n",
    "    \n",
    "    # Create a dataset and save the data\n",
    "    save_file = file_name[:-5] + '_analysis.hdf5'\n",
    "\n",
    "\n",
    "    with h5py.File(os.path.join(save_folder, save_file), \"w\") as f:\n",
    "        dset = f.create_group(\"analysis data\")\n",
    "        dset.attrs['N particles'] = filament.Np\n",
    "        dset.attrs['radius'] = filament.radius\n",
    "        dset.attrs['bond length'] = filament.b0\n",
    "        dset.attrs['spring constant'] = filament.k\n",
    "        dset.attrs['kappa_hat'] = filament.kappa_hat\n",
    "        dset.attrs['force strength'] = filament.F0\n",
    "        dset.attrs['stresslet strength'] = filament.S0\n",
    "        dset.attrs['potDipole strength'] = filament.D0\n",
    "        dset.attrs['simulation type'] = filament.sim_type\n",
    "        dset.attrs['activity time scale'] = filament.activity_timescale\n",
    "        dset.attrs['viscosity'] = filament.mu\n",
    "        dset.attrs['boundary condition 0'] = filament.bc[0]\n",
    "        dset.attrs['boundary condition 1'] = filament.bc[-1]\n",
    "        dset.attrs['Sim complete'] = simulation_completed\n",
    "        \n",
    "        dset.attrs['constant phase'] = phase\n",
    "        dset.create_dataset(\"Tip angles\", data = angles)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "frozen-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s][Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "100%|██████████| 21/21 [00:00<00:00, 208.98it/s]\n",
      "[Parallel(n_jobs=12)]: Done   4 out of  21 | elapsed:   10.6s remaining:   45.0s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  21 | elapsed:   19.4s remaining:   38.9s\n",
      "[Parallel(n_jobs=12)]: Done  10 out of  21 | elapsed:   22.3s remaining:   24.6s\n",
      "[Parallel(n_jobs=12)]: Done  13 out of  21 | elapsed:   24.7s remaining:   15.2s\n",
      "[Parallel(n_jobs=12)]: Done  16 out of  21 | elapsed:   27.9s remaining:    8.7s\n",
      "[Parallel(n_jobs=12)]: Done  19 out of  21 | elapsed:   31.2s remaining:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done  21 out of  21 | elapsed:   31.9s finished\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "num_cores = 12\n",
    "\n",
    "results = Parallel(n_jobs=num_cores,  verbose=10)(delayed(run_filament_analysis)(file) for file in tqdm(files_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-huntington",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
